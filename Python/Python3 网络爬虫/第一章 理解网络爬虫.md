# 第一章 理解网络爬虫
## 爬虫的定义

1. 网络爬虫是一种按照一定的规则自动地抓取网络信息的程序或者脚本。
2. 简单来说，网络爬虫就是根据一定的算法实现编程开发，主要通过 URL 实现数据的抓取和发掘。
3. 传统的爬虫有百度、Google、必应等搜索引擎，这类通用的搜索引擎都有自己的核心算法。
4. 通用的搜索引擎存在一定的局限性：

- 不同的搜索引擎对于同一个搜索会有不同的结果，搜索出来的结果未必是用户需要的信息。
- 通用的搜索引擎扩大了网络覆盖率，但有限的搜索引擎服务器资源与无限的网络数据资源之间的矛盾将进一步加深。
- 随着网络上数据形式繁多和网络技术的不断发展，图片、数据库、音频、视频多媒体等不同数据大量出现，通用搜索引擎往往对这些信息含量密集且具有一定结构的数据无能为力，不能很好地发现和获取。

5. 为了得到准确的数据，定向抓取相关网页资源的聚焦爬虫应运而生。
6. 聚焦爬虫是一个自动下载网页的程序，可根据设定的抓取目标有目的性地访问互联网上的网页与相关的 URL ，从而获取所需要的信息。
7. 与通用爬虫不同，聚焦爬虫并不追求全面的覆盖率，而是抓取与某一特定内容相关的网页，为面向特定的用户提供准备数据资源。

## 爬虫的类型
1. 网络爬虫根据系统结构和开发技术大致可以分为 4 种类型：通用网络爬虫、聚焦网络爬虫、增量式网络爬虫和深层网络爬虫。
2. 通用网络爬虫又称全网爬虫，常见的有百度、Google、必应等搜索引擎，爬行对象从一些初始 URL 扩充到整个网站，主要为门户站点搜索引擎和大型网站服务采取数据，具有以下特点：

- 由于商业的原因，引擎的算法是不会对外公布的。
- 这类网络爬虫的爬取范围和数量巨大，对于爬取速度和存储空间要求较高，爬取页面的顺序要求相对较低。
- 待刷新的页面太多，通常采用并行工作方式，但需要较长时间才能刷新一次页面。
- 存在一定缺陷，通用网络爬虫适用于为搜索引擎搜索广泛的需求。

3. 聚焦网络爬虫又称主题网络爬虫，是选择性地爬取根据需求的主题相关页面的网络爬虫。与通用网络爬虫相比，聚焦爬虫只需要爬取与主题相关的页面，不需要广泛地覆盖无关的网页，很好地满足一些特定人群对特定领域信息的需求。
4. 增量式网络爬虫是指对已下载的网页采取增量式更新和只爬取新产生或者已经发生变化的网页的爬虫，它能够在一定程度上保证所爬取的页面尽可能是新的页面。只会在需要的时候爬取新产生或者发生更新的页面，并不重新下载没有发生变化的页面，可有效减少数据下载量，及时更新已爬取的网页，减少时间和空间上的耗费，但增加了爬取算法的复杂度和实现难度，基本上这类爬虫在实际开发中不太普及。
5. 深层网络爬虫是大部分内容不能通过静态 URL 获取的、隐藏在搜索表单后的、只有用户提交了一些关键词才能获得的网络页面。
6. 聚焦网络爬虫、增量式网络爬虫和深层网络爬虫可以通俗地归纳为一类，因为这类爬虫都是定向爬取数据。相比与通用爬虫，这类爬虫比较有目的性，也就是网络上经常说的网络爬虫，而通用爬虫在网络上通常被称为搜索引擎。

## 爬虫的原理
1. 通用网络爬虫的实现原理：
- 获取初始的 URL，初始的 URL 地址可以人为地指定，也可以由用户指定的某个或某几个初始爬取网页决定。
- 根据初始的 URL 爬取页面并获得新的 URL 。获取初始的 URL 地址之后，先爬取当前 URL 地址中的网页信息，然后解析网页信息内容，将网页存储到原始数据库中，并且在当前获得的网页信息里发现新的 URL 地址，存放于一个 URL 队列里面。
- 从 URL 队列中读取新的 URL，从而获取新的网页信息，同时在新的网页中获取新的 URL 并重复上述的爬取过程。
- 满足爬虫系统设置的停止条件时，停止爬取。在编写爬虫时，一般会设置相应的停止条件，爬虫则会在停止条件满足时停止爬取。如果没有设置停止条件，一直到无法获取新的 URL 地址为止。
2. 聚焦网络爬虫的实现原理：
- 指定爬取方案。在聚焦网络爬虫中，首先要依据需求定义聚焦网络爬虫爬取的目标以及整体的爬取方案。
- 设定初始的 URL
- 根据初始的 URL 抓取页面，并获取新的 URL。
- 从新的 URL 中过滤掉与需求无关的 URL，将过滤后的 URL 放入 URL 队列中。
- 在 URL 队列中，根据搜索算法确定 URL 的优先级，并确定下一步要爬取的URL地址。因为聚焦网络爬虫具有目的性，所以 URL 的爬取顺序不同会导致的执行效率不同。
- 得到新的 URL ，将新的 URL 重现上述爬取过程。
- 满足系统中设置的停止条件或无法获取新的 URL 地址，停止爬行。

## 爬虫的搜索策略
### 深度优先搜索
1. 深度优先搜索是在开发爬虫早期使用较多的方法，目的是达到被搜索结构的叶结点（那些不包含任何超级 URL 的 HTML 文件）。在一个 HTML 文件中，当一个 URL 被选择后，被选 URL 将执行深度优先搜索，搜索后得到新的 HTML 文件，再从新的 HTML 获取新的 URL 进行搜索，以此类推，不断地爬取 HTML 中的 URL ，直到 HTML 中没有 URL 为止。
2. 深度优先搜索沿着 HTML 文件中的 URL 走到不能深入为止，然后返回到某一个 HTML 文件，再继续选择该 HTML 文件中的其他 URL 。当不再有其他 URL 可选择时，说明搜索已经已经结束。其优点能遍历一个 Web 站点或深层嵌套的文档集合。缺点是因为 Web 结构相当深，有可能造成一旦进去再也出不来的情况发生。

### 宽度优先搜索
1. 宽度优先搜索是搜索完一个 Web 页面中所有的 URL ，然后继续搜索下一层，直到底层为止。例如，首页中有 3 个 URL ，爬虫会选择其中之一，处理相应的页面之后，然后返回首页再爬取第二个 URL ，处理相应的的页面，最后返回首页爬取第三个 URL ，处理第三个 URL 对应的页面。
2. 一旦一层上的所有 URL 都被选择过，就可以开始在刚才处理过的页面中搜索其余的 URL ，这就保证了对浅层的优先处理。当遇到一个无穷尽的深层分支时，不会导致陷进深层文档中出不来的情况发生。宽度优先搜索策略还有一个优点，能够在两个页面之间找到最短路径。
3. 宽度优先搜索策略通常是实现爬虫的最佳策略，因为它容易实现，而且具备大多数期望的功能。

### 聚焦爬虫的爬行策略
1. 聚焦爬虫的爬行策略只针对某个特定主题的页面，根据最好优先原则进行访问，快速、有效地获得更多与主题相关的页面，主要通过内容与 Web 的 URL 结构指导进行页面抓取。

## 爬虫的开发流程
1. 一般情况下，爬虫的开发流程如下：
- 需求说明。任何程序开发都离不开需求说明，爬虫开发也是如此，需求说明包含功能说明、功能的业务逻辑等详细说明。爬虫的需求说明要明确告知开发人员需要爬取哪些数据、数据存储方式以及爬虫的爬取效率。
- 爬虫开发计划。根据爬虫的需求说明制定相关的开发计划，比如选择爬虫的开发工具、功能模块化设计、设计爬虫运行模式等一系列开发明细。
- 爬虫的功能开发。根据开发计划编写相应的功能代码。以功能模块化设计为依据，每个功能模块以函数或类的形式表示，再将各个模块进行组合，从而实现整个爬虫功能的开发。
- 爬虫的部署与交付。程序开发完成后就可以进行部署上线或交付客户。部署和交付的方式有多种，比如打包 exe 程序、GUI 界面或定时执行等。

## 本章小结
1. 网络爬虫的类型理论上分为 4 类，但实际上主要是两大类：通用爬虫和聚焦爬虫。
2. 通用爬虫主要有 Google、百度、必应等搜索引擎，主要以核心算法为主导，学习成本相对较高，聚焦爬虫就是定向爬取数据，是有目的性的爬虫，学习成本相对较低。
